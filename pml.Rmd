### PML - Writeup
#### Summary of steps 
The basic steps in involved are given below. Implementation section shows each of these steps as comments.
   1. Loading the training set - pml-training.csv
   2. Cleaning up the dataset to remove the columns/predictors with near zero variance and where there are lot of missing values or NAs. near zero variance predictors take unique values across samples, are non-informative as well as break the model.
   3. From the training set above, create a model training set and a cross-validation set in the ratio of 70:30 percent.
   4. Using the model training set above, train a model using RandomForest
   5. Run varImp() on the generated model to checkout the significance of predictors
   6. Run the cross-validation set against the generated model to predict the model accuracy.
   7. Check the predictions from this cross-validated set using a confusion matrix.
   8. If the accuracy is > 0.9; run the real test set from pml-testing.csv

#### Expected out of sample error
The out of sample or out of bag error for the model is 0.21% given by model$finalModel:
OOB estimate of  error rate: 0.21%.
The confusion matrix for cross-validation shows a percentage error of 14/(1674+1133+1022+963+1079)*100 = 0.23%. 

With a > 0.9 accuracy, 95% of the out of sample data should lie within the CI generated by the model. It is appropriately shown below for the cross-validation confusion matrix.

#### Confusion Matrix and Statistics on cross-validation data

<!-- html table generated in R 3.1.1 by xtable 1.7-4 package -->
<!-- Mon Sep 22 00:48:54 2014 -->
<table border=1>
<tr> <th>  </th> <th> A </th> <th> B </th> <th> C </th> <th> D </th> <th> E </th>  </tr>
  <tr> <td align="right"> A </td> <td align="right"> 1674 </td> <td align="right">   6 </td> <td align="right">   0 </td> <td align="right">   0 </td> <td align="right">   0 </td> </tr>
  <tr> <td align="right"> B </td> <td align="right">   0 </td> <td align="right"> 1133 </td> <td align="right">   4 </td> <td align="right">   0 </td> <td align="right">   0 </td> </tr>
  <tr> <td align="right"> C </td> <td align="right">   0 </td> <td align="right">   0 </td> <td align="right"> 1022 </td> <td align="right">   0 </td> <td align="right">   0 </td> </tr>
  <tr> <td align="right"> D </td> <td align="right">   0 </td> <td align="right">   0 </td> <td align="right">   0 </td> <td align="right"> 963 </td> <td align="right">   3 </td> </tr>
  <tr> <td align="right"> E </td> <td align="right">   0 </td> <td align="right">   0 </td> <td align="right">   0 </td> <td align="right">   1 </td> <td align="right"> 1079 </td> </tr>
   </table>

Overall Statistics
                                         
               Accuracy : 0.9976         
                 95% CI : (0.996, 0.9987)
    No Information Rate : 0.2845         
    P-Value [Acc > NIR] : < 2.2e-16
    
#### Implementation 
```{r model,echo=TRUE,cache=TRUE,results='hide'}
##1. Loading the training set - pml-training.csv
df <- read.csv("/Users/mridul/coursera/PREDMACHLEARN/pml-training.csv")
##2. Cleaning up the dataset to remove the columns/predictors with near zero variance and where there are lot of missing values or NAs. near zero variance predictors take unique values across samples, are non-informative as well as break the model.
#explore <- describe(df)
library(caret)
removecols <- nearZeroVar(df)
nearzerodf <- df[,-removecols]
cleandf <- subset(nearzerodf, select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,var_accel_forearm,amplitude_pitch_forearm,min_pitch_forearm,max_picth_forearm,var_yaw_dumbbell,stddev_yaw_dumbbell,avg_yaw_dumbbell,var_pitch_dumbbell,stddev_pitch_dumbbell,avg_pitch_dumbbell,var_roll_dumbbell,stddev_roll_dumbbell,avg_roll_dumbbell,var_accel_dumbbell,amplitude_pitch_dumbbell,amplitude_roll_dumbbell,min_pitch_dumbbell,min_roll_dumbbell,max_picth_dumbbell,max_roll_dumbbell,max_roll_belt,max_picth_belt,min_roll_belt,min_pitch_belt,amplitude_roll_belt,amplitude_pitch_belt,var_total_accel_belt, avg_roll_belt,stddev_roll_belt, var_roll_belt,avg_pitch_belt, stddev_pitch_belt,var_pitch_belt,avg_yaw_belt,stddev_yaw_belt,var_yaw_belt,var_accel_arm,max_picth_arm,max_yaw_arm,min_yaw_arm,amplitude_yaw_arm))

traindf <- cleandf
#3. From the training set above, create a model training set and a cross-validation set in the ratio of 70:30 percent.
select <- createDataPartition(traindf$classe, p = 0.7, list = FALSE)
dataTrain <- traindf[select,]
dataCV <- traindf[-select,]
#4. Using the model training set above, train a model using RandomForest
model <- train(classe ~ ., data=dataTrain, method="rf", verbose=FALSE)
summary(model)
```
```{r predictions,echo=TRUE,results='hide'}
#5. Run varImp() on the generated model to checkout the significance of predictors
sign_pred <- varImp(model)
#6. Run the cross-validation set against the generated model to predict the model accuracy.
predictions <- predict(model,dataCV)
#7. Check the predictions from this cross-validated set using a confusion matrix.Results analyzed in the section above (Confusion Matrix and Statistics on cross-validation data)
confusionMatrix(predictions,dataCV$classe)
# Additionally, you can use the cross validation to check the model
cv <- trainControl(method = "repeatedcv", repeats = 1, number=4, allowParallel=TRUE, verboseIter=TRUE) 
preObj <- c("center", "scale") 
modFit_rf <- train(classe~., data=dataTrain, preProcess=preObj, method = 'rf', trControl =cv) 
summary(modFit_rf)

#8. If the accuracy is > 0.9(which has been analyzed in section "Expected out of sample error"); run the real test set from pml-testing.csv
dataTest <- read.csv("/Users/mridul/coursera/PREDMACHLEARN/pml-testing.csv")
cleanset <- dataTest[,names(cleandf)[1:53]]
clean <- cbind(cleanset,dataTest$problem_id)
#Do not show the answer for pml-testing.csv. It works though, with 100% accuracy on pml-testing.csv
realpredictions <- predict(model,clean)
summary(realpredictions)
```
